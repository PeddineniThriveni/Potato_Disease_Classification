{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e42c3f4-0d52-4ab6-94a1-6049dbc776b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models,layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5861a5b-9d03-4c9c-9177-a485c9a3ec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE=256\n",
    "BATCH_SIZE=32\n",
    "channels=3\n",
    "EPOCHS=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a6881a7-9633-43bd-ba07-03da3b067f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2152 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "tf_dataset=tf.keras.preprocessing.image_dataset_from_directory(\"PlantVillage\",)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d16d9a4-5ef3-4ea4-9396-85a2182e9a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7fce46c-0622-4b8e-b3e6-4213c75ed319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy']\n"
     ]
    }
   ],
   "source": [
    "classnames=tf_dataset.class_names\n",
    "print(classnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1731e52d-9ba5-4142-95de-55a6c7023740",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes=len(classnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94c0c0b4-3cca-4026-aa01-e0c91d2624f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[109. 100. 101.]\n",
      "  [110. 101. 102.]\n",
      "  [115. 106. 107.]\n",
      "  ...\n",
      "  [141. 135. 139.]\n",
      "  [143. 137. 141.]\n",
      "  [145. 139. 143.]]\n",
      "\n",
      " [[116. 107. 108.]\n",
      "  [127. 118. 119.]\n",
      "  [128. 119. 120.]\n",
      "  ...\n",
      "  [142. 136. 140.]\n",
      "  [144. 138. 142.]\n",
      "  [146. 140. 144.]]\n",
      "\n",
      " [[ 97.  88.  89.]\n",
      "  [108.  99. 100.]\n",
      "  [107.  98.  99.]\n",
      "  ...\n",
      "  [143. 137. 141.]\n",
      "  [144. 138. 142.]\n",
      "  [145. 139. 143.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[132. 127. 133.]\n",
      "  [121. 116. 122.]\n",
      "  [125. 120. 126.]\n",
      "  ...\n",
      "  [170. 165. 172.]\n",
      "  [168. 163. 170.]\n",
      "  [165. 160. 167.]]\n",
      "\n",
      " [[132. 127. 133.]\n",
      "  [120. 115. 121.]\n",
      "  [135. 130. 136.]\n",
      "  ...\n",
      "  [166. 161. 168.]\n",
      "  [166. 161. 168.]\n",
      "  [162. 157. 164.]]\n",
      "\n",
      " [[142. 137. 143.]\n",
      "  [126. 121. 127.]\n",
      "  [138. 133. 139.]\n",
      "  ...\n",
      "  [172. 167. 174.]\n",
      "  [175. 170. 177.]\n",
      "  [172. 167. 174.]]], shape=(256, 256, 3), dtype=float32)\n",
      "tf.Tensor([1 0 0 0 1 1 2 1 0 1 1 1 2 1 0 0 1 1 1 2 0 1 2 2 2 0 1 0 2 0 1 0], shape=(32,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for image,label in tf_dataset.take(1):\n",
    "    print(image[0])\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf866bf8-4be7-4bb5-b2ce-af4034d382e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_partitions_tf(tf_dataset,train_split=0.8,val_split=0.1,test_split=0.1,shuffle=True,shuffle_size=1000):\n",
    "    ds_size=len(tf_dataset)\n",
    "    if shuffle:\n",
    "       tf_dataset= tf_dataset.shuffle(shuffle_size,seed=12)\n",
    "    train_size=int(train_split*ds_size)\n",
    "    train_ds=tf_dataset.take(train_size)\n",
    "    val_size=int(val_split*ds_size)\n",
    "    val_ds=tf_dataset.skip(train_size).take(val_size)\n",
    "    test_ds=tf_dataset.skip(train_size).skip(val_size)\n",
    "    return train_ds,val_ds,test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed328640-f7bf-4676-b3b0-bba2e6e9664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds,val_ds,test_ds=get_dataset_partitions_tf(tf_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "906c5e37-4fc6-4316-9e23-476d2c7b1981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_TakeDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "print(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97ead050-3825-42d4-94b8-4dd60038c0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddd8b7ad-d385-45dc-a7e1-6dd0f0cc29a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.400000000000006"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "68*0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ae62431-9c33-4762-861b-45bad062f4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd23c0ac-95f3-469c-a174-29d5c051ee66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "973c33ce-c0b5-4ab5-9883-a43ed158ac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds=train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds=val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_ds=test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4f0acab-6a2e-42a3-9dc2-51824ab7f23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_and_rescale=tf.keras.Sequential([\n",
    "    layers.Resizing(IMAGE_SIZE,IMAGE_SIZE),\n",
    "    layers.Rescaling(1.0/255)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2a1c066-38ad-40a4-89fa-9af674905e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation=tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6acc3491-2661-4b8b-bc6b-2edf0f5310d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\Downloads\\Potato_disease\\training\\me_env\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "input_shape=(BATCH_SIZE,IMAGE_SIZE,IMAGE_SIZE,channels)\n",
    "model=models.Sequential([\n",
    "    resize_and_rescale,\n",
    "    data_augmentation,\n",
    "    layers.Conv2D(32,(3,3),activation='relu',input_shape=input_shape),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64,kernel_size=(3,3),activation='relu'),\n",
    "     layers.MaxPooling2D((2,2)),\n",
    "     layers.Conv2D(64,kernel_size=(3,3),activation='relu'),\n",
    "     layers.MaxPooling2D((2,2)),\n",
    "     layers.Conv2D(64,kernel_size=(3,3),activation='relu'),\n",
    "     layers.MaxPooling2D((2,2)),\n",
    "     layers.Conv2D(64,kernel_size=(3,3),activation='relu'),\n",
    "     layers.MaxPooling2D((2,2)),\n",
    "     layers.Conv2D(64,kernel_size=(3,3),activation='relu'),\n",
    "     layers.MaxPooling2D((2,2)),\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(64,activation='relu'),\n",
    "      layers.Dense(n_classes,activation='softmax'),\n",
    "])\n",
    "model.build(input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13b9d37a-587a-4d16-9501-3faa4e44cc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd54f66d-f662-42f0-83e3-627bb10d8562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 3s/step - accuracy: 0.4716 - loss: 0.9194 - val_accuracy: 0.7344 - val_loss: 0.7848\n",
      "Epoch 2/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 3s/step - accuracy: 0.6763 - loss: 0.6923 - val_accuracy: 0.8698 - val_loss: 0.3965\n",
      "Epoch 3/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 3s/step - accuracy: 0.7946 - loss: 0.4636 - val_accuracy: 0.8542 - val_loss: 0.3316\n",
      "Epoch 4/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 3s/step - accuracy: 0.8578 - loss: 0.3499 - val_accuracy: 0.8125 - val_loss: 0.4132\n",
      "Epoch 5/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 3s/step - accuracy: 0.8904 - loss: 0.2927 - val_accuracy: 0.9115 - val_loss: 0.2219\n",
      "Epoch 6/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 3s/step - accuracy: 0.8790 - loss: 0.2717 - val_accuracy: 0.9167 - val_loss: 0.2274\n",
      "Epoch 7/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 3s/step - accuracy: 0.9235 - loss: 0.1930 - val_accuracy: 0.8802 - val_loss: 0.4684\n",
      "Epoch 8/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 3s/step - accuracy: 0.9096 - loss: 0.2307 - val_accuracy: 0.9115 - val_loss: 0.2200\n",
      "Epoch 9/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 3s/step - accuracy: 0.9377 - loss: 0.1767 - val_accuracy: 0.9323 - val_loss: 0.1782\n",
      "Epoch 10/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 3s/step - accuracy: 0.9365 - loss: 0.1696 - val_accuracy: 0.9427 - val_loss: 0.1631\n",
      "Epoch 11/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 3s/step - accuracy: 0.9387 - loss: 0.1426 - val_accuracy: 0.9531 - val_loss: 0.1625\n",
      "Epoch 12/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 3s/step - accuracy: 0.9231 - loss: 0.2058 - val_accuracy: 0.9479 - val_loss: 0.1192\n",
      "Epoch 13/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 3s/step - accuracy: 0.9455 - loss: 0.1560 - val_accuracy: 0.9375 - val_loss: 0.1407\n",
      "Epoch 14/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 3s/step - accuracy: 0.9451 - loss: 0.1485 - val_accuracy: 0.9583 - val_loss: 0.1680\n",
      "Epoch 15/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 3s/step - accuracy: 0.9590 - loss: 0.1140 - val_accuracy: 0.9583 - val_loss: 0.1163\n",
      "Epoch 16/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 3s/step - accuracy: 0.9582 - loss: 0.1150 - val_accuracy: 0.9479 - val_loss: 0.1692\n",
      "Epoch 17/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 3s/step - accuracy: 0.9565 - loss: 0.1194 - val_accuracy: 0.9688 - val_loss: 0.0771\n",
      "Epoch 18/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 3s/step - accuracy: 0.9442 - loss: 0.1423 - val_accuracy: 0.9531 - val_loss: 0.1407\n",
      "Epoch 19/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 3s/step - accuracy: 0.9637 - loss: 0.1009 - val_accuracy: 0.9271 - val_loss: 0.1780\n",
      "Epoch 20/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 3s/step - accuracy: 0.9302 - loss: 0.1927 - val_accuracy: 0.9688 - val_loss: 0.1053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b5b16bbf10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds,epochs=EPOCHS,batch_size=BATCH_SIZE,verbose=1,validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d452d739-9e8a-4ce3-bf39-13e720406413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 630ms/step - accuracy: 0.9669 - loss: 0.0773\n"
     ]
    }
   ],
   "source": [
    "scores=model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63add709-2e45-4eb7-bfd4-6db9b0965c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08169567584991455, 0.9609375]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "308d5ceb-e46c-4118-9c2c-0ed0f09dbef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '../models/2'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1879834950496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1879877369920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1879877565632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1879877565808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1879877566160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1879877718208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1879877719264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1879877714160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1879877720848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1879877718560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1879877722432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1879877720144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1879877724016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1879877721728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1879877723840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1879877727536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1879877719088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1879877718912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "model_version=2\n",
    "model.export(f\"../models/{model_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7845c19-df07-41db-804e-af5213d81c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (me_env)",
   "language": "python",
   "name": "me_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
